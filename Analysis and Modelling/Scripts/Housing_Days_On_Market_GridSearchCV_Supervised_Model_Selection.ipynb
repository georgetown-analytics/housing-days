{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Housing Days On Market Supervised Model Selection\n",
    "\n",
    "## Information\n",
    "\n",
    "Housing related data sources were combined in the project SQLite database. The output CSV file is analyzed here. \n",
    "\n",
    "### Environment Information:\n",
    "\n",
    "Environment used for coding is as follow:\n",
    "\n",
    "Oracle VM VirtualBox running Ubuntu (guest) on Windows 10 (host).\n",
    "\n",
    "Current conda install:\n",
    "\n",
    "               platform : linux-64\n",
    "          conda version : 4.2.13\n",
    "       conda is private : False\n",
    "      conda-env version : 4.2.13\n",
    "    conda-build version : 1.20.0\n",
    "         python version : 2.7.11.final.0\n",
    "       requests version : 2.9.1\n",
    "       \n",
    "Package requirements:\n",
    "\n",
    "dill : 0.2.4, numpy : 1.11.2, pandas : 0.19.1, matplotlib : 1.5.1, scipy : 0.18.1, seaborn : 0.7.0, scikit-image : 0.12.3, scikit-learn : 0.18.1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Package(s) Used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import dill\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LassoCV, RidgeCV, ElasticNetCV, SGDRegressor, HuberRegressor, PassiveAggressiveRegressor, TheilSenRegressor\n",
    "from sklearn.metrics import explained_variance_score, mean_absolute_error, mean_squared_error, r2_score   \n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data and Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Fetching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import data csv into dataframe\n",
    "df = pd.read_csv('df_prep_for_feature_selection_output.csv')\n",
    "df = df.drop('Unnamed: 0', axis = 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_2 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Performing feature selection on full dataset, resulted in best_score ~ 0.1.\n",
    "# Qcutting to separate out data.\n",
    "# qcut value = 1 is dataset as is.\n",
    "\n",
    "# Qcut DOMP target data\n",
    "df_2['qcut_DOMP'] = pd.qcut(df_2['DOMP'], 1, labels = False)\n",
    "# Print out total row counts for each group\n",
    "print(df_2['qcut_DOMP'].value_counts())\n",
    "# Select specific range\n",
    "df_2 = df_2[df_2['qcut_DOMP'] == 0]\n",
    "# Save dataframe to disk\n",
    "df_2.to_csv('df_feature_selection_save_point.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Copy dataframe for dropping columns and determining categorical columns\n",
    "df_3 = df_2.copy()\n",
    "# Drop target column and qcut column for test-train-split\n",
    "df_3 = df_3.drop('DOMP', axis=1)\n",
    "df_3 = df_3.drop('qcut_DOMP', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Checking for grouped categorical columns\n",
    "#df_3.columns[0:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Columns that are not scaled since they are categorical\n",
    "# cat_df = df_3[['MS_IsTitleI','ES_IsTitleI','BasementY/N']]\n",
    "# cat_df_2 = df_3.ix[:,39:43]\n",
    "# cat_df_3 = df_3.ix[:,48:52]\n",
    "# cat_df_4 = df_3.ix[:,57:61]\n",
    "# cat_df_5 = df_3.ix[:,93:178]\n",
    "# cat_df_6 = pd.concat([cat_df,cat_df_2,cat_df_3,cat_df_4,cat_df_5],axis=1)\n",
    "# CATEGORICAL = [x for x in cat_df_6.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CATEGORICAL = ['BasementY/N','ES_IsCharter','ES_IsMagnet','ES_IsTitleI','ES_IsVirtual',\n",
    "               'HS_IsCharter','HS_IsMagnet','HS_IsTitleI','HS_IsVirtual','MS_IsCharter',\n",
    "               'MS_IsMagnet','MS_IsTitleI','MS_IsVirtual','zip_20001','zip_20002','zip_20004',\n",
    "               'zip_20005','zip_20007','zip_20008','zip_20009','zip_20010','zip_20011',\n",
    "               'zip_20012','zip_20015','zip_20017','zip_20018','zip_20019','zip_20020',\n",
    "               'zip_20032','zip_20036','zip_20037','ldmonth_1','ldmonth_2','ldmonth_3',\n",
    "               'ldmonth_4','ldmonth_5','ldmonth_6','ldmonth_7','ldmonth_8','ldmonth_9',\n",
    "               'ldmonth_10','ldmonth_11','ldmonth_12','ldday_1','ldday_2','ldday_3',\n",
    "               'ldday_4','ldday_5','ldday_6','ldday_7','ldday_8','ldday_9','ldday_10',\n",
    "               'ldday_11','ldday_12','ldday_13','ldday_14','ldday_15','ldday_16','ldday_17',\n",
    "               'ldday_18','ldday_19','ldday_20','ldday_21','ldday_22','ldday_23','ldday_24',\n",
    "               'ldday_25','ldday_26','ldday_27','ldday_28','ldday_29','ldday_30','ldday_31',\n",
    "               'ESSR_0.0','ESSR_1.0','ESSR_2.0','ESSR_3.0','ESSR_4.0','ESSR_5.0','HSSR_0.0',\n",
    "               'HSSR_1.0','HSSR_2.0','HSSR_3.0','HSSR_4.0','MSSR_0.0','MSSR_1.0','MSSR_2.0',\n",
    "               'MSSR_3.0','MSSR_4.0','MSSR_5.0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters for estimator GridSearch\n",
    "\n",
    "# MAE not used for rfr,etr,or gbr. Program would crash or hit memory limitations \n",
    "# if used with MSE.\n",
    "rfr_parameters = {'n_estimators':[100], \n",
    "              'criterion':['mse'],\n",
    "              'max_features':['auto'],\n",
    "              'min_samples_leaf':[1,2,5],\n",
    "              'random_state':[1]}\n",
    "\n",
    "etr_parameters = {'n_estimators':[100], \n",
    "              'criterion':['mse'],\n",
    "              'max_features':['auto'],\n",
    "              'min_samples_leaf':[1,2,5],\n",
    "              'random_state':[1]}\n",
    "\n",
    "gbr_parameters = {'loss':['ls','lad','huber'], \n",
    "              'learning_rate':[0.1],\n",
    "              'n_estimators':[100],\n",
    "              'criterion':['friedman_mse','mse'],\n",
    "              'min_samples_leaf':[1,2,5],\n",
    "              'max_features':['auto'],    \n",
    "              'random_state':[1]}\n",
    "\n",
    "sgdr_parameters = {'loss':['squared_loss','huber','epsilon_insensitive'], \n",
    "              'alpha':[0.0001,0.001,0.01,0.1,1.0],\n",
    "              'fit_intercept':[True,False],\n",
    "              'n_iter':[5,10],     \n",
    "              'random_state':[1]}\n",
    "\n",
    "tsr_parameters = {'fit_intercept':[True,False],\n",
    "              'max_iter':[400],     \n",
    "              'random_state':[1]}\n",
    "\n",
    "par_parameters = {'loss':['epsilon_insensitive','squared_epsilon_insensitive'],\n",
    "              'C':[0.001,0.01,0.1,1.0,10.0],\n",
    "              'fit_intercept':[True,False],\n",
    "              'n_iter':[5,10],     \n",
    "              'random_state':[1]}\n",
    "\n",
    "hr_parameters = {'alpha':[0.0001,0.001,0.01,0.1,1.0],\n",
    "              'fit_intercept':[True,False],\n",
    "              'max_iter':[200]}\n",
    "\n",
    "lcv_parameters = {'eps':[0.001,0.01,0.1],\n",
    "              'fit_intercept':[True,False],\n",
    "              'cv':[4],\n",
    "              'max_iter':[25000],    \n",
    "              'random_state':[1]}\n",
    "\n",
    "rcv_parameters = {'alphas':[np.array([0.1,1.0,10.0])],\n",
    "              'fit_intercept':[True,False],\n",
    "              'cv':[4]}\n",
    "\n",
    "encv_parameters = {'l1_ratio':[0.2,0.4,0.6,0.8],\n",
    "              'eps':[0.001,0.01,0.1],\n",
    "              'fit_intercept':[True,False],\n",
    "              'cv':[4],\n",
    "              'max_iter':[25000],    \n",
    "              'random_state':[1]}\n",
    "\n",
    "knnr_parameters = {'n_neighbors':[2,4,6,8,10,12,14,16,18,20], \n",
    "              'weights':['uniform','distance'],\n",
    "              'algorithm':['ball_tree','kd_tree']}\n",
    "\n",
    "svr_parameters = {'C':[0.01,0.1,1.0], \n",
    "              'kernel':['poly','rbf'],\n",
    "              'degree':[1,2,3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gridsearch_model_selection(df,model_estimator,model_estimator_str,grid_params,CATEGORICAL):\n",
    "\n",
    "    \"\"\"\n",
    "    Perform GridSearchCV on different estimators using the dataframe from feature selection.\n",
    "    The function test-train-splits the dataset, and performs GridSearchCV. Individual models\n",
    "    are saved as dills, and the regression metrics are saved to csv.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Start clock for run time\n",
    "    start  = time.time()\n",
    "    \n",
    "    # Copy dataframe\n",
    "    df_2 = df.copy()\n",
    "    \n",
    "    # Drop target column and qcut column for test-train-split\n",
    "    df_2 = df_2.drop('DOMP', axis=1)\n",
    "    df_2 = df_2.drop('qcut_DOMP', axis=1)\n",
    "    \n",
    "    # Test-train split. Using 70/30% split.\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_2, df['DOMP'], train_size=0.70,\n",
    "                                                    random_state=1)    \n",
    "    \n",
    "    # Standardizing training and testing data. Standardized separately to avoid information\n",
    "    # leaking from the training set to the testing set. Categorical data not scaled.\n",
    "    for i in X_train.columns.difference(CATEGORICAL):\n",
    "        X_train[i] = StandardScaler().fit_transform(X_train[i].values.reshape(-1,1))\n",
    "\n",
    "    for i in X_test.columns.difference(CATEGORICAL):\n",
    "        X_test[i] = StandardScaler().fit_transform(X_test[i].values.reshape(-1,1))\n",
    "        \n",
    "    # GridSearchCV for estimator\n",
    "    grid = GridSearchCV(model_estimator, grid_params, cv = 12, n_jobs = -1, verbose=True)\n",
    "    grid.fit(X_train, y_train)\n",
    "    \n",
    "    # Print out best score and respective parameters\n",
    "    print('Best score from GridSearchCV for estimator '+model_estimator_str+' is ',grid.best_score_)\n",
    "    #print \"Best model parameters from GridSearch are \",grid.best_estimator_.get_params()\n",
    "    \n",
    "    # Save model to disk\n",
    "    dill.dump(grid, open('GridSearchCV_model_selection_'+model_estimator_str+'_no_prior_feature_selection', 'wb'))\n",
    "    dill.dump(grid.best_estimator_, open('GridSearchCV_model_selection_best_'+model_estimator_str+'_no_prior_feature_selection', 'wb'))\n",
    "\n",
    "    # Predicted target values\n",
    "    y_pred = grid.predict(X_test)\n",
    "   \n",
    "    # Store regression metrics\n",
    "    exp_var_score = explained_variance_score(y_test, y_pred)\n",
    "    #r2 = r2_score(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)    \n",
    "\n",
    "    # Create dataframe to save regression metrics\n",
    "    df_combination = pd.DataFrame(columns = {'estimator','r2_score','exp_var_score',\n",
    "                                             'mae','mse','process_time'})\n",
    "    estimator_list_lst = []\n",
    "    exp_var_score_lst = []\n",
    "    r2_score_lst = []\n",
    "    mae_lst = []\n",
    "    mse_lst = []\n",
    "    process_time_lst = []\n",
    "    \n",
    "    # Save metrics to separate lists for inclusion in dataframe. Saving directly to dataframe\n",
    "    # resulted in typeerrors being flagged.\n",
    "    estimator_list_lst.append(model_estimator_str)\n",
    "    exp_var_score_lst.append(exp_var_score)\n",
    "    r2_score_lst.append(grid.best_score_) # best_score here is the r2_score, since GridSearchCV\n",
    "                                          # uses the default score metrics from the estimator \n",
    "    mae_lst.append(mae)\n",
    "    mse_lst.append(mse)    \n",
    "    process_time_lst.append(time.time()-start)\n",
    "    \n",
    "    # Add lists as series to dataframe, and save file to disk.\n",
    "    df_combination['estimator'] = estimator_list_lst\n",
    "    df_combination['exp_var_score'] = exp_var_score_lst\n",
    "    df_combination['r2_score'] = r2_score_lst\n",
    "    df_combination['mae'] = mae_lst\n",
    "    df_combination['mse'] = mse_lst\n",
    "    df_combination['process_time'] = process_time_lst\n",
    "    df_combination.to_csv('GridSearchCV_model_selection_'+model_estimator_str+'_no_prior_feature_selection_regression_metrics.csv')\n",
    "    \n",
    "    # Print run time\n",
    "    print(\"\\nBuild and Validation took {:0.3f} seconds\\n\".format(time.time()-start))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gridsearch_model_selection(df_2,SGDRegressor(),'SGDR',sgdr_parameters,CATEGORICAL)\n",
    "gridsearch_model_selection(df_2,TheilSenRegressor(),'TSR',tsr_parameters,CATEGORICAL)\n",
    "gridsearch_model_selection(df_2,PassiveAggressiveRegressor(),'PAR',par_parameters,CATEGORICAL)\n",
    "gridsearch_model_selection(df_2,HuberRegressor(),'HR',hr_parameters,CATEGORICAL)\n",
    "gridsearch_model_selection(df_2,LassoCV(),'LCV',lcv_parameters,CATEGORICAL)\n",
    "gridsearch_model_selection(df_2,RidgeCV(),'RCV',rcv_parameters,CATEGORICAL)\n",
    "gridsearch_model_selection(df_2,ElasticNetCV(),'ENCV',encv_parameters,CATEGORICAL)\n",
    "gridsearch_model_selection(df_2,KNeighborsRegressor(),'KNNR',knnr_parameters,CATEGORICAL)\n",
    "gridsearch_model_selection(df_2,RandomForestRegressor(),'RFR',rfr_parameters,CATEGORICAL)\n",
    "gridsearch_model_selection(df_2,ExtraTreesRegressor(),'ETR',etr_parameters,CATEGORICAL)\n",
    "gridsearch_model_selection(df_2,GradientBoostingRegressor(),'GBR',gbr_parameters,CATEGORICAL)\n",
    "gridsearch_model_selection(df_2,SVR(),'SVR',svr_parameters,CATEGORICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
